{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from chainercv.evaluations import eval_detection_voc\n",
    "from models import *\n",
    "from config import cfg\n",
    "from datasets import VOCDectectionDataset\n",
    "from torchvision.ops import roi_pool, nms\n",
    "from sklearn.metrics import average_precision_score\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "year='2007'\n",
    "pretrained='alexnet'\n",
    "if pretrained == 'alexnet':\n",
    "    model = Combined_Alexnet()\n",
    "elif pretrained == 'vgg16':\n",
    "    model = Combined_VGG16()\n",
    "model.to(cfg.DEVICE)\n",
    "\n",
    "checkpoints = torch.load(cfg.PATH.PT_PATH + \"OK_WholeModel_2007_alexnet_50_39to50.pt\")\n",
    "model.load_state_dict(checkpoints['whole_model_state_dict'])\n",
    "\n",
    "\n",
    "testdata = VOCDectectionDataset(\"~/data/\", year, 'test')\n",
    "test_loader = data.DataLoader(testdata, 1, shuffle=False)\n",
    "\n",
    "log_file = cfg.PATH.LOG_PATH + f\"Validate_{pretrained}\" + \".txt\"\n",
    "write_log(log_file, f\"model_name: OICR_{pretrained}\")\n",
    "\n",
    "y_pred = []\n",
    "y_true = []\n",
    "\n",
    "total_pred_boxes = []\n",
    "total_pred_labels = []\n",
    "total_pred_scores = []\n",
    "total_true_boxes = []\n",
    "total_true_labels = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ae7ec271e5a4a6d9c6d40e44ff58aa2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluation', max=4952.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1455, 4])\n",
      "torch.Size([1, 1808, 4])\n",
      "torch.Size([1, 2150, 4])\n",
      "torch.Size([1, 1959, 4])\n",
      "torch.Size([1, 1350, 4])\n",
      "torch.Size([1, 1272, 4])\n",
      "torch.Size([1, 1618, 4])\n",
      "torch.Size([1, 674, 4])\n",
      "torch.Size([1, 1393, 4])\n",
      "torch.Size([1, 1887, 4])\n",
      "torch.Size([1, 1544, 4])\n",
      "torch.Size([1, 1170, 4])\n",
      "torch.Size([1, 1851, 4])\n",
      "torch.Size([1, 2195, 4])\n",
      "torch.Size([1, 1594, 4])\n",
      "torch.Size([1, 1096, 4])\n",
      "torch.Size([1, 1310, 4])\n",
      "torch.Size([1, 1996, 4])\n",
      "torch.Size([1, 1557, 4])\n",
      "torch.Size([1, 1308, 4])\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-2bcdfaaca207>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mn_imgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_regions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregion\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Evaluation\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mregion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.4/lib/python3.7/site-packages/tqdm/notebook.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    216\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 218\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtqdm_notebook\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    219\u001b[0m                 \u001b[0;31m# return super(tqdm...) will not catch exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.4/lib/python3.7/site-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1128\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1129\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1130\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1131\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.4/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.4/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    383\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    386\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.4/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.4/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/work/OICR-pytorch/src/datasets.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    212\u001b[0m                 \u001b[0mnew_region\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mregion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m                 \u001b[0mnew_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mratio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresize_img_smallside\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 214\u001b[0;31m                 \u001b[0mresize_box\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_region\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mratio\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    215\u001b[0m                 \u001b[0mn_images\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_img\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m                 \u001b[0mn_regions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_region\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/work/OICR-pytorch/src/datasets.py\u001b[0m in \u001b[0;36mresize_box\u001b[0;34m(boxes, ratio)\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0mbox\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mratio\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mbox\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0mbox\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mratio\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mbox\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0mbox\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mratio\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mbox\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0mbox\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mratio\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mbox\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for n_imgs, gt, n_regions, region in tqdm(test_loader, \"Evaluation\"):\n",
    "    print(region.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28cbe7eb5fb54e1b921f8db4b2c71d25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluation', max=4952.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Avg AP: [0.00393585 0.00426226 0.00434099 0.01177118 0.0003898  0.0024014\n",
      " 0.01523217 0.00258811 0.00114284 0.00050489 0.00122735 0.00403291\n",
      " 0.00543998 0.00777342 0.02104173 0.0007268  0.00022942 0.00249056\n",
      " 0.09291598 0.00076029]\n",
      "Avg mAP: 0.009160395602624268\n",
      "Testset classify AP is [0.03213300835861144, 0.06482426124086477, 0.04507938326670338, 0.025076178779248986, 0.053398649136742284, 0.052665821896442415, 0.29436950007400287, 0.0442165632427279, 0.08054694670438828, 0.02109691924240181, 0.039208610897063734, 0.06946067955831821, 0.05457246261337535, 0.07636931859253493, 0.596575768479525, 0.045919154173019866, 0.012290772645594965, 0.038726416411538886, 0.054662867331567826, 0.04931596494262753]\n",
      "Testset classify mAP is 0.08752546237936502\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    n = len(cfg.DATA.SCALES)\n",
    "    for n_imgs, gt, n_regions, region in tqdm(test_loader, \"Evaluation\"):\n",
    "#         print(region.shape)\n",
    "        region = region.to(cfg.DEVICE)\n",
    "        avg_scores = torch.zeros((len(region[0]), 20), dtype=torch.float32)\n",
    "        \n",
    "#         avg_scores = torch.zeros((len(region[0]), 20), dtype=torch.float32)\n",
    "        scales = len(cfg.DATA.SCALES)\n",
    "        k = cfg.K\n",
    "        for i in range(scales):\n",
    "            per_img = n_imgs[i].to(cfg.DEVICE)\n",
    "            per_region = n_regions[i].to(cfg.DEVICE)\n",
    "            refine_scores, proposal_scores = model(per_img, per_region)\n",
    "            avg_scores += sum(refine_scores)[:, :20].detach().cpu()\n",
    "#             avg_scores += proposal_scores.cpu()\n",
    "        avg_scores /= (3 * scales)\n",
    "        \n",
    "    \n",
    "        gt = gt.numpy()[0]\n",
    "        gt_boxex = gt[:, :4]\n",
    "        gt_labels = gt[:, -1]\n",
    "    \n",
    "        gt_labels_onehot = np.zeros(20)\n",
    "        for label in gt_labels:\n",
    "            gt_labels_onehot[int(label)] = 1\n",
    "        y_pred.append(avg_scores.sum(0).detach().cpu().numpy().tolist())\n",
    "        y_true.append(gt_labels_onehot.tolist())\n",
    "\n",
    "        per_pred_boxes = []\n",
    "        per_pred_scores = []\n",
    "        per_pred_labels = []\n",
    "        \n",
    "        region = region[0].cpu()\n",
    "        \n",
    "        for i in range(20):\n",
    "            cls_scores = avg_scores[:, i]\n",
    "            cls_region = region\n",
    "            \n",
    "#             score_filter = cls_scores > 1e-6\n",
    "#             cls_scores = cls_scores[score_filter]\n",
    "#             cls_region = cls_region[score_filter]\n",
    "            \n",
    "            if cls_scores.numel() == 0 or cls_region.numel() == 0:\n",
    "                continue\n",
    "\n",
    "            nms_filter = nms(cls_region, cls_scores, 0.3)\n",
    "            per_pred_boxes.append(cls_region[nms_filter].numpy())\n",
    "            per_pred_scores.append(cls_scores[nms_filter].numpy())\n",
    "            per_pred_labels.append(np.full(len(nms_filter), i, dtype=np.int32))\n",
    "            \n",
    "        total_pred_boxes.append(np.concatenate(per_pred_boxes, axis=0))\n",
    "        total_pred_scores.append(np.concatenate(per_pred_scores, axis=0))\n",
    "        total_pred_labels.append(np.concatenate(per_pred_labels, axis=0))\n",
    "        total_true_boxes.append(gt_boxex)\n",
    "        total_true_labels.append(gt_labels)\n",
    "        \n",
    "    result = eval_detection_voc(\n",
    "        total_pred_boxes,\n",
    "        total_pred_labels,\n",
    "        total_pred_scores,\n",
    "        total_true_boxes,\n",
    "        total_true_labels,\n",
    "        iou_thresh=0.5,\n",
    "        use_07_metric=True,\n",
    "    )\n",
    "    print(f\"Avg AP: {result['ap']}\")\n",
    "    print(f\"Avg mAP: {result['map']}\")\n",
    "#         write_log(log_file, f\"Avg AP: {result['ap']}\")\n",
    "#         write_log(log_file, f\"Avg mAP: {result['map']}\")\n",
    "    cls_ap = []\n",
    "    y_pred = np.array(y_pred)\n",
    "    y_true = np.array(y_true)\n",
    "    for i in range(20):\n",
    "        cls_ap.append(average_precision_score(y_true[:,i], y_pred[:,i]))\n",
    "    print(f\"Testset classify AP is {str(cls_ap)}\")\n",
    "    print(f\"Testset classify mAP is {str(sum(cls_ap)/20)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "alexnet \n",
    "* 28 epoch\n",
    "    * 0 ~ 12 -> 1e-3\n",
    "    * 12 ~ 28 ->1e-4\n",
    "    * 无 gn\n",
    "   \n",
    "Avg AP: [0.00250069 0.00268959 0.00593918 0.01238983 0.00037103 0.00520011\n",
    " 0.05094934 0.0025402  0.00145823 0.00060337 0.00230691 0.00568992\n",
    " 0.00343817 0.00329781 0.02234189 0.00066166 0.00028807 0.00268314\n",
    " 0.00682418 0.0011487 ]\n",
    " \n",
    "Avg mAP: 0.006666101292653241\n",
    "\n",
    "Testset classify AP is [0.031194349732388986, 0.0572540864953559, 0.04718262608471971, 0.027607681272222413, 0.05280227671969535, 0.05056773772898126, 0.2652140489262636, 0.04465063139115444, 0.08254710888368796, 0.020101784423735305, 0.04062878114999654, 0.07325480353317904, 0.05545111365999122, 0.0861678516354079, 0.5328506722903639, 0.05101622583523328, 0.014253184515077868, 0.03858852637022686, 0.05871458627724349, 0.04824319210879111]\n",
    "\n",
    "Testset classify mAP is 0.08391456345168583\n",
    "\n",
    "-----\n",
    "\n",
    "\n",
    "vgg16 联合训练 oicr + GroupNorm\n",
    "\n",
    "Avg AP: [0.09051399 0.18203187 0.08157918 0.03588963 0.00938754 0.19129429\n",
    " 0.1791767  0.26907684 0.00336021 0.10906965 0.08120123 0.18342123\n",
    " 0.06307971 0.15827458 0.03537233 0.0963341  0.02026587 0.13565538\n",
    " 0.23144397 0.01841274]\n",
    " \n",
    "Avg mAP: 0.10874205257675588\n",
    "\n",
    "Testset classify AP is [0.861379509457694, 0.5464344555413259, 0.8003924640583021, 0.7809129075735384, 0.17323967359198622, 0.6694490297538691, 0.8282779424696932, 0.8666258007735645, 0.3152865776140701, 0.5462951295709837, 0.3261202627186228, 0.7544566528512925, 0.37742541489619386, 0.4449411781005752, 0.8810713641118815, 0.5723464026070882, 0.6089818297132764, 0.6139789231030357, 0.8293171620131501, 0.7585100285661969]\n",
    "\n",
    "Testset classify mAP is 0.6277721354543171\n",
    "\n",
    "\n",
    "vgg16 结果\n",
    "\n",
    "Avg AP: [0.07594125 0.15202542 0.11302452 0.01443283 0.09229122 0.18310884\n",
    " 0.17307478 0.19584398 0.04892519 0.03835734 0.10568615 0.10578527\n",
    " 0.03219307 0.11462246 0.04233103 0.02550928 0.04346568 0.12203952\n",
    " 0.18385794 0.02253245]\n",
    " \n",
    "Avg mAP: 0.0942524098604717"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Avg AP: [0.0380435  0.09586847 0.02967028 0.01421967 0.02488741 0.12029387\n",
    " 0.12345616 0.14256291 0.00230058 0.09248682 0.09352449 0.11741401\n",
    " 0.10741478 0.08556007 0.0268022  0.09133743 0.01528107 0.05298027\n",
    " 0.13549627 0.03642921]\n",
    " \n",
    "Avg mAP: 0.07230147397022946"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Avg AP: [0.06553017 0.11218434 0.04370746 0.01982238 0.0250097  0.1920574\n",
    " 0.184809   0.21933456 0.00361981 0.09866133 0.1002228  0.16470673\n",
    " 0.13001323 0.14395161 0.04144958 0.09434894 0.02223967 0.06508374\n",
    " 0.20686167 0.04100427]\n",
    "\n",
    "Avg mAP: 0.09873091926663828"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([], size=(0, 4))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cls_region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cls_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cls_scores.numel() == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
