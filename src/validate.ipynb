{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from chainercv.evaluations import eval_detection_voc\n",
    "from models import MIDN_Alexnet, MIDN_VGG16, OICR\n",
    "from config import cfg\n",
    "from datasets import VOCDectectionDataset\n",
    "from torchvision.ops import roi_pool, nms\n",
    "from sklearn.metrics import average_precision_score\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "year='2007'\n",
    "pretrained='vgg16'\n",
    "oicr = None\n",
    "if pretrained == 'alexnet':\n",
    "    midn = MIDN_Alexnet()\n",
    "elif pretrained == 'vgg16':\n",
    "    midn = MIDN_VGG16()\n",
    "midn.to(cfg.DEVICE)\n",
    "\n",
    "oicr = OICR(cfg.K)\n",
    "oicr.to(cfg.DEVICE)\n",
    "\n",
    "midn_checkpoints = torch.load(cfg.PATH.PT_PATH + \"Model_2007_vgg16_20_old.pt\")\n",
    "midn.load_state_dict(midn_checkpoints['midn_model_state_dict'])\n",
    "oicr.load_state_dict(midn_checkpoints['oicr_model_state_dict'])\n",
    "\n",
    "\n",
    "testdata = VOCDectectionDataset(\"~/data/\", year, 'test')\n",
    "test_loader = data.DataLoader(testdata, 1, shuffle=False)\n",
    "\n",
    "log_file = cfg.PATH.LOG_PATH + f\"Validate_{pretrained}\" + \".txt\"\n",
    "write_log(log_file, f\"model_name: OICR_{pretrained}\")\n",
    "\n",
    "y_pred = []\n",
    "y_true = []\n",
    "\n",
    "total_pred_boxes = []\n",
    "total_pred_labels = []\n",
    "total_pred_scores = []\n",
    "total_true_boxes = []\n",
    "total_true_labels = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26c15ffd648140ac9fe1dada7f626ed4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluation', max=4952.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Avg AP: [0.06543496 0.13772103 0.11171478 0.01045832 0.09219723 0.16593716\n",
      " 0.17469437 0.12095688 0.03295824 0.03254094 0.05913931 0.08997836\n",
      " 0.03253466 0.11140212 0.04204161 0.02496726 0.04479538 0.1121503\n",
      " 0.18538617 0.02084201]\n",
      "Avg mAP: 0.08339255502995957\n",
      "Testset classify AP is [0.7686124651884377, 0.6377192036212179, 0.6931169515273672, 0.7769481020981058, 0.45303283092926716, 0.707234311634705, 0.8481437394589839, 0.7803962350291742, 0.5253592185531923, 0.6637031229904103, 0.5576079120049549, 0.7550650626487099, 0.5030783657096044, 0.5952222735886301, 0.9176201364654784, 0.5581422241756182, 0.6086998789970127, 0.5823820529295567, 0.7571790186201262, 0.7552319592696703]\n",
      "Testset classify mAP is 0.6722247532720114\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    midn.eval()\n",
    "    oicr.eval()\n",
    "    for n_imgs, gt, n_regions, region in tqdm(test_loader, \"Evaluation\"):\n",
    "#         print(region.shape)\n",
    "        region = region.to(cfg.DEVICE)\n",
    "        avg_scores = torch.zeros((len(region[0]), 20), dtype=torch.float32)\n",
    "        for i in range(3):\n",
    "            per_img = n_imgs[i].to(cfg.DEVICE)\n",
    "            per_region = n_regions[i].to(cfg.DEVICE)\n",
    "            fc7, combined_scores = midn(per_img, per_region)\n",
    "            refine_scores = oicr(fc7)\n",
    "            avg_scores = (sum(refine_scores).cpu())/ cfg.K\n",
    "        avg_scores /= 3\n",
    "        \n",
    "#         avg_scores = torch.zeros((len(region[0]), 20), dtype=torch.float32)\n",
    "#         for i in range(3):\n",
    "#             per_img = n_imgs[i].to(cfg.DEVICE)\n",
    "#             per_region = n_regions[i].to(cfg.DEVICE)\n",
    "#             fc7, combined_scores = midn(per_img, per_region)\n",
    "#             avg_scores += avg_scores.cpu()\n",
    "#         avg_scores /= (3 * 1)\n",
    "        \n",
    "    \n",
    "        gt = gt.numpy()[0]\n",
    "        gt_boxex = gt[:, :4]\n",
    "        gt_labels = gt[:, -1]\n",
    "    \n",
    "        gt_labels_onehot = np.zeros(20)\n",
    "        for label in gt_labels:\n",
    "            gt_labels_onehot[int(label)] = 1\n",
    "        y_pred.append(avg_scores.sum(0).detach().cpu().numpy().tolist())\n",
    "        y_true.append(gt_labels_onehot.tolist())\n",
    "\n",
    "        per_pred_boxes = []\n",
    "        per_pred_scores = []\n",
    "        per_pred_labels = []\n",
    "        \n",
    "        region = region[0].cpu()\n",
    "        \n",
    "        for i in range(20):\n",
    "            cls_scores = avg_scores[:, i]\n",
    "            cls_region = region\n",
    "\n",
    "            nms_filter = nms(cls_region, cls_scores, 0.3)\n",
    "            per_pred_boxes.append(cls_region[nms_filter].numpy())\n",
    "            per_pred_scores.append(cls_scores[nms_filter].numpy())\n",
    "            per_pred_labels.append(np.full(len(nms_filter), i, dtype=np.int32))\n",
    "            \n",
    "        total_pred_boxes.append(np.concatenate(per_pred_boxes, axis=0))\n",
    "        total_pred_scores.append(np.concatenate(per_pred_scores, axis=0))\n",
    "        total_pred_labels.append(np.concatenate(per_pred_labels, axis=0))\n",
    "        total_true_boxes.append(gt_boxex)\n",
    "        total_true_labels.append(gt_labels)\n",
    "        \n",
    "    result = eval_detection_voc(\n",
    "        total_pred_boxes,\n",
    "        total_pred_labels,\n",
    "        total_pred_scores,\n",
    "        total_true_boxes,\n",
    "        total_true_labels,\n",
    "        iou_thresh=0.5,\n",
    "        use_07_metric=True,\n",
    "    )\n",
    "    print(f\"Avg AP: {result['ap']}\")\n",
    "    print(f\"Avg mAP: {result['map']}\")\n",
    "#         write_log(log_file, f\"Avg AP: {result['ap']}\")\n",
    "#         write_log(log_file, f\"Avg mAP: {result['map']}\")\n",
    "    cls_ap = []\n",
    "    y_pred = np.array(y_pred)\n",
    "    y_true = np.array(y_true)\n",
    "    for i in range(20):\n",
    "        cls_ap.append(average_precision_score(y_true[:,i], y_pred[:,i]))\n",
    "    print(f\"Testset classify AP is {str(cls_ap)}\")\n",
    "    print(f\"Testset classify mAP is {str(sum(cls_ap)/20)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "vgg16 结果\n",
    "\n",
    "Avg AP: [0.07594125 0.15202542 0.11302452 0.01443283 0.09229122 0.18310884\n",
    " 0.17307478 0.19584398 0.04892519 0.03835734 0.10568615 0.10578527\n",
    " 0.03219307 0.11462246 0.04233103 0.02550928 0.04346568 0.12203952\n",
    " 0.18385794 0.02253245]\n",
    " \n",
    "Avg mAP: 0.0942524098604717"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Avg AP: [0.0380435  0.09586847 0.02967028 0.01421967 0.02488741 0.12029387\n",
    " 0.12345616 0.14256291 0.00230058 0.09248682 0.09352449 0.11741401\n",
    " 0.10741478 0.08556007 0.0268022  0.09133743 0.01528107 0.05298027\n",
    " 0.13549627 0.03642921]\n",
    " \n",
    "Avg mAP: 0.07230147397022946"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Avg AP: [0.06553017 0.11218434 0.04370746 0.01982238 0.0250097  0.1920574\n",
    " 0.184809   0.21933456 0.00361981 0.09866133 0.1002228  0.16470673\n",
    " 0.13001323 0.14395161 0.04144958 0.09434894 0.02223967 0.06508374\n",
    " 0.20686167 0.04100427]\n",
    "\n",
    "Avg mAP: 0.09873091926663828"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 693, 4])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "region.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
