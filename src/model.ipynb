{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data\n",
    "import torchvision\n",
    "from torchvision.ops import roi_pool\n",
    "from wsddn import *\n",
    "from collections import OrderedDict \n",
    "from models import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "states = torch.load(\"../checkpoints/states.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(states, '../checkpoints/states')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_parameters(module):\n",
    "    if type(module) in [nn.Conv2d, nn.Linear]:\n",
    "        torch.nn.init.normal_(module.weight, mean=0.0, std=1e-2)\n",
    "        torch.nn.init.zeros_(module.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_parameters(src, target):\n",
    "    assert src.weight.size() == target.weight.size()\n",
    "    assert src.bias.size() == target.bias.size()\n",
    "    src.weight = target.weight\n",
    "    src.bias = target.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Combined_Alexnet(nn.Module):\n",
    "    def __init__(self, K=3, groups=4):\n",
    "        super(Combined_Alexnet, self).__init__()\n",
    "        self.K = K\n",
    "        self.groups = groups\n",
    "#         alexnet = torchvision.models.alexnet(pretrained=True)\n",
    "        wsddn_alexnet = WSDDN_Alexnet()\n",
    "        wsddn_alexnet.load_state_dict(torch.load(\"../pretrained/eb_2007_wsddn_alexnet.pt\"))\n",
    "        self.pretrained_features = nn.Sequential(*list(wsddn_alexnet.features[:5]._modules.values()))\n",
    "        self.new_features = nn.Sequential(OrderedDict([\n",
    "            ('conv3', nn.Conv2d(192, 384, kernel_size=3, stride=1, padding=2, dilation=2)),\n",
    "            ('relu3', nn.ReLU(inplace=True)),\n",
    "            ('conv4', nn.Conv2d(384, 256, kernel_size=3, stride=1, padding=2, dilation=2)),\n",
    "            ('relu4', nn.ReLU(inplace=True)),\n",
    "            ('conv5', nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=2, dilation=2)),\n",
    "            ('relu5', nn.ReLU(inplace=True)),\n",
    "        ]))\n",
    "        \n",
    "        copy_parameters(self.new_features.conv3, wsddn_alexnet.features[6])\n",
    "        copy_parameters(self.new_features.conv4, wsddn_alexnet.features[8])\n",
    "        copy_parameters(self.new_features.conv5, wsddn_alexnet.features[10])\n",
    "        \n",
    "        self.roi_size = (6, 6)\n",
    "        self.roi_spatial_scale= 0.125\n",
    "        \n",
    "        \n",
    "        self.fc67 = nn.Sequential(*list(wsddn_alexnet.fc67._modules.values()))\n",
    "        self.fc8c = wsddn_alexnet.fc8c\n",
    "        self.fc8d = wsddn_alexnet.fc8d\n",
    "        self.c_softmax = nn.Softmax(dim=1)\n",
    "        self.d_softmax = nn.Softmax(dim=0)\n",
    "        for i in range(self.K):\n",
    "            self.add_module(\n",
    "                f'refine{i}',\n",
    "                nn.Sequential(OrderedDict([\n",
    "#                     (f'groupNorm', nn.GroupNorm(self.groups, 4096)),\n",
    "                    (f'ic_score{i}', nn.Linear(4096, 21)),\n",
    "                    (f'ic_probs{i}', nn.Softmax(dim=1))\n",
    "                ])))\n",
    "            \n",
    "    def forward(self, x, regions):\n",
    "        regions = [regions[0]] # roi_pool require [Tensor(K, 4)]\n",
    "        R = len(regions[0])\n",
    "        features = self.new_features(self.pretrained_features(x))\n",
    "        pool_features = roi_pool(features, regions, self.roi_size, self.roi_spatial_scale).view(R, -1)\n",
    "        fc7 = self.fc67(pool_features)\n",
    "        c_score = self.c_softmax(self.fc8c(fc7))\n",
    "        d_score = self.d_softmax(self.fc8d(fc7))\n",
    "        proposal_scores = c_score * d_score\n",
    "\n",
    "        refine_scores = []\n",
    "        for i in range(self.K):\n",
    "            refine_scores.append(self._modules[f'refine{i}'](fc7))\n",
    "        return refine_scores, proposal_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (1): ReLU(inplace=True)\n",
       "  (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (3): ReLU(inplace=True)\n",
       "  (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (6): ReLU(inplace=True)\n",
       "  (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (8): ReLU(inplace=True)\n",
       "  (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (11): ReLU(inplace=True)\n",
       "  (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (13): ReLU(inplace=True)\n",
       "  (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (15): ReLU(inplace=True)\n",
       "  (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (18): ReLU(inplace=True)\n",
       "  (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (20): ReLU(inplace=True)\n",
       "  (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (22): ReLU(inplace=True)\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.pretrained_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_in_models(model, pretrained_data):\n",
    "    model.pretrained_features[0].weight.data = pretrained_data['model']['Conv_Body.conv1.0.weight']\n",
    "    model.pretrained_features[0].bias.data   = pretrained_data['model']['Conv_Body.conv1.0.bias']\n",
    "\n",
    "    model.pretrained_features[2].weight.data = pretrained_data['model']['Conv_Body.conv1.2.weight']\n",
    "    model.pretrained_features[2].bias.data   = pretrained_data['model']['Conv_Body.conv1.2.bias']\n",
    "\n",
    "    model.pretrained_features[5].weight.data = pretrained_data['model']['Conv_Body.conv2.0.weight']\n",
    "    model.pretrained_features[5].bias.data   = pretrained_data['model']['Conv_Body.conv2.0.bias']\n",
    "\n",
    "    model.pretrained_features[7].weight.data = pretrained_data['model']['Conv_Body.conv2.2.weight']\n",
    "    model.pretrained_features[7].bias.data   = pretrained_data['model']['Conv_Body.conv2.2.bias']\n",
    "\n",
    "    model.pretrained_features[10].weight.data = pretrained_data['model']['Conv_Body.conv3.0.weight']\n",
    "    model.pretrained_features[10].bias.data   = pretrained_data['model']['Conv_Body.conv3.0.bias']\n",
    "\n",
    "    model.pretrained_features[12].weight.data = pretrained_data['model']['Conv_Body.conv3.2.weight']\n",
    "    model.pretrained_features[12].bias.data   = pretrained_data['model']['Conv_Body.conv3.2.bias']\n",
    "\n",
    "    model.pretrained_features[14].weight.data = pretrained_data['model']['Conv_Body.conv3.4.weight']\n",
    "    model.pretrained_features[14].bias.data   = pretrained_data['model']['Conv_Body.conv3.4.bias']\n",
    "\n",
    "    model.pretrained_features[17].weight.data = pretrained_data['model']['Conv_Body.conv4.0.weight']\n",
    "    model.pretrained_features[17].bias.data   = pretrained_data['model']['Conv_Body.conv4.0.bias']\n",
    "\n",
    "    model.pretrained_features[19].weight.data = pretrained_data['model']['Conv_Body.conv4.2.weight']\n",
    "    model.pretrained_features[19].bias.data   = pretrained_data['model']['Conv_Body.conv4.2.bias']\n",
    "\n",
    "    model.pretrained_features[21].weight.data = pretrained_data['model']['Conv_Body.conv4.4.weight']\n",
    "    model.pretrained_features[21].bias.data   = pretrained_data['model']['Conv_Body.conv4.4.bias']\n",
    "\n",
    "    model.new_features[0].weight.data = pretrained_data['model']['Conv_Body.conv5.0.weight']\n",
    "    model.new_features[0].bias.data   = pretrained_data['model']['Conv_Body.conv5.0.bias']\n",
    "\n",
    "    model.new_features[2].weight.data = pretrained_data['model']['Conv_Body.conv5.2.weight']\n",
    "    model.new_features[2].bias.data   = pretrained_data['model']['Conv_Body.conv5.2.bias']\n",
    "\n",
    "    model.new_features[4].weight.data = pretrained_data['model']['Conv_Body.conv5.4.weight']\n",
    "    model.new_features[4].bias.data   = pretrained_data['model']['Conv_Body.conv5.4.bias']\n",
    "\n",
    "    model.fc67[0].weight.data = pretrained_data['model']['Box_Head.fc1.weight']\n",
    "    model.fc67[0].bias.data   = pretrained_data['model']['Box_Head.fc1.bias']\n",
    "\n",
    "    model.fc67[3].weight.data = pretrained_data['model']['Box_Head.fc2.weight']\n",
    "    model.fc67[3].bias.data   = pretrained_data['model']['Box_Head.fc2.bias']\n",
    "\n",
    "    model.fc8d.weight.data = pretrained_data['model']['Box_MIL_Outs.mil_score0.weight']\n",
    "    model.fc8d.bias.data   = pretrained_data['model']['Box_MIL_Outs.mil_score0.bias']\n",
    "\n",
    "    model.fc8c.weight.data = pretrained_data['model']['Box_MIL_Outs.mil_score1.weight']\n",
    "    model.fc8c.bias.data   = pretrained_data['model']['Box_MIL_Outs.mil_score1.bias']\n",
    "\n",
    "    model.ic_score1.weight.data = pretrained_data['model']['Box_Refine_Outs.refine_score.0.weight']\n",
    "    model.ic_score1.bias.data   = pretrained_data['model']['Box_Refine_Outs.refine_score.0.bias']\n",
    "\n",
    "    model.ic_score2.weight.data = pretrained_data['model']['Box_Refine_Outs.refine_score.1.weight']\n",
    "    model.ic_score2.bias.data   = pretrained_data['model']['Box_Refine_Outs.refine_score.1.bias']\n",
    "\n",
    "    model.ic_score3.weight.data = pretrained_data['model']['Box_Refine_Outs.refine_score.2.weight']\n",
    "    model.ic_score3.bias.data   = pretrained_data['model']['Box_Refine_Outs.refine_score.2.bias']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_data = torch.load(\"../checkpoints/voc2007.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.pretrained_features[0].weight.data = pretrained_data['model']['Conv_Body.conv1.0.weight']\n",
    "model.pretrained_features[0].bias.data   = pretrained_data['model']['Conv_Body.conv1.0.bias']\n",
    "\n",
    "model.pretrained_features[2].weight.data = pretrained_data['model']['Conv_Body.conv1.2.weight']\n",
    "model.pretrained_features[2].bias.data   = pretrained_data['model']['Conv_Body.conv1.2.bias']\n",
    "\n",
    "model.pretrained_features[5].weight.data = pretrained_data['model']['Conv_Body.conv2.0.weight']\n",
    "model.pretrained_features[5].bias.data   = pretrained_data['model']['Conv_Body.conv2.0.bias']\n",
    "\n",
    "model.pretrained_features[7].weight.data = pretrained_data['model']['Conv_Body.conv2.2.weight']\n",
    "model.pretrained_features[7].bias.data   = pretrained_data['model']['Conv_Body.conv2.2.bias']\n",
    "\n",
    "model.pretrained_features[10].weight.data = pretrained_data['model']['Conv_Body.conv3.0.weight']\n",
    "model.pretrained_features[10].bias.data   = pretrained_data['model']['Conv_Body.conv3.0.bias']\n",
    "\n",
    "model.pretrained_features[12].weight.data = pretrained_data['model']['Conv_Body.conv3.2.weight']\n",
    "model.pretrained_features[12].bias.data   = pretrained_data['model']['Conv_Body.conv3.2.bias']\n",
    "\n",
    "model.pretrained_features[14].weight.data = pretrained_data['model']['Conv_Body.conv3.4.weight']\n",
    "model.pretrained_features[14].bias.data   = pretrained_data['model']['Conv_Body.conv3.4.bias']\n",
    "\n",
    "model.pretrained_features[17].weight.data = pretrained_data['model']['Conv_Body.conv4.0.weight']\n",
    "model.pretrained_features[17].bias.data   = pretrained_data['model']['Conv_Body.conv4.0.bias']\n",
    "\n",
    "model.pretrained_features[19].weight.data = pretrained_data['model']['Conv_Body.conv4.2.weight']\n",
    "model.pretrained_features[19].bias.data   = pretrained_data['model']['Conv_Body.conv4.2.bias']\n",
    "\n",
    "model.pretrained_features[21].weight.data = pretrained_data['model']['Conv_Body.conv4.4.weight']\n",
    "model.pretrained_features[21].bias.data   = pretrained_data['model']['Conv_Body.conv4.4.bias']\n",
    "\n",
    "model.new_features[0].weight.data = pretrained_data['model']['Conv_Body.conv5.0.weight']\n",
    "model.new_features[0].bias.data   = pretrained_data['model']['Conv_Body.conv5.0.bias']\n",
    "\n",
    "model.new_features[2].weight.data = pretrained_data['model']['Conv_Body.conv5.2.weight']\n",
    "model.new_features[2].bias.data   = pretrained_data['model']['Conv_Body.conv5.2.bias']\n",
    "\n",
    "model.new_features[4].weight.data = pretrained_data['model']['Conv_Body.conv5.4.weight']\n",
    "model.new_features[4].bias.data   = pretrained_data['model']['Conv_Body.conv5.4.bias']\n",
    "\n",
    "model.fc67[0].weight.data = pretrained_data['model']['Box_Head.fc1.weight']\n",
    "model.fc67[0].bias.data   = pretrained_data['model']['Box_Head.fc1.bias']\n",
    "\n",
    "model.fc67[3].weight.data = pretrained_data['model']['Box_Head.fc2.weight']\n",
    "model.fc67[3].bias.data   = pretrained_data['model']['Box_Head.fc2.bias']\n",
    "\n",
    "model.fc8d.weight.data = pretrained_data['model']['Box_MIL_Outs.mil_score0.weight']\n",
    "model.fc8d.bias.data   = pretrained_data['model']['Box_MIL_Outs.mil_score0.bias']\n",
    "\n",
    "model.fc8c.weight.data = pretrained_data['model']['Box_MIL_Outs.mil_score1.weight']\n",
    "model.fc8c.bias.data   = pretrained_data['model']['Box_MIL_Outs.mil_score1.bias']\n",
    "\n",
    "model.ic_score1.weight.data = pretrained_data['model']['Box_Refine_Outs.refine_score.0.weight']\n",
    "model.ic_score1.bias.data   = pretrained_data['model']['Box_Refine_Outs.refine_score.0.bias']\n",
    "\n",
    "model.ic_score2.weight.data = pretrained_data['model']['Box_Refine_Outs.refine_score.1.weight']\n",
    "model.ic_score2.bias.data   = pretrained_data['model']['Box_Refine_Outs.refine_score.1.bias']\n",
    "\n",
    "model.ic_score3.weight.data = pretrained_data['model']['Box_Refine_Outs.refine_score.2.weight']\n",
    "model.ic_score3.bias.data   = pretrained_data['model']['Box_Refine_Outs.refine_score.2.bias']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in pretrained_data['model'].items():\n",
    "    print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Combined_VGG16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base.features.0.weight\n",
      "base.features.0.bias\n",
      "base.features.2.weight\n",
      "base.features.2.bias\n",
      "base.features.5.weight\n",
      "base.features.5.bias\n",
      "base.features.7.weight\n",
      "base.features.7.bias\n",
      "base.features.10.weight\n",
      "base.features.10.bias\n",
      "base.features.12.weight\n",
      "base.features.12.bias\n",
      "base.features.14.weight\n",
      "base.features.14.bias\n",
      "base.features.17.weight\n",
      "base.features.17.bias\n",
      "base.features.19.weight\n",
      "base.features.19.bias\n",
      "base.features.21.weight\n",
      "base.features.21.bias\n",
      "base.features.24.weight\n",
      "base.features.24.bias\n",
      "base.features.26.weight\n",
      "base.features.26.bias\n",
      "base.features.28.weight\n",
      "base.features.28.bias\n",
      "base.classifier.0.weight\n",
      "base.classifier.0.bias\n",
      "base.classifier.3.weight\n",
      "base.classifier.3.bias\n",
      "base.classifier.6.weight\n",
      "base.classifier.6.bias\n",
      "features.0.weight\n",
      "features.0.bias\n",
      "features.2.weight\n",
      "features.2.bias\n",
      "features.5.weight\n",
      "features.5.bias\n",
      "features.7.weight\n",
      "features.7.bias\n",
      "features.10.weight\n",
      "features.10.bias\n",
      "features.12.weight\n",
      "features.12.bias\n",
      "features.14.weight\n",
      "features.14.bias\n",
      "features.17.weight\n",
      "features.17.bias\n",
      "features.19.weight\n",
      "features.19.bias\n",
      "features.21.weight\n",
      "features.21.bias\n",
      "features.24.weight\n",
      "features.24.bias\n",
      "features.26.weight\n",
      "features.26.bias\n",
      "features.28.weight\n",
      "features.28.bias\n",
      "fcs.0.weight\n",
      "fcs.0.bias\n",
      "fcs.3.weight\n",
      "fcs.3.bias\n",
      "fc_c.weight\n",
      "fc_c.bias\n",
      "fc_d.weight\n",
      "fc_d.bias\n",
      "fc_ic_score.weight\n",
      "fc_ic_score.bias\n",
      "fc_ic_score1.weight\n",
      "fc_ic_score1.bias\n",
      "fc_ic_score2.weight\n",
      "fc_ic_score2.bias\n"
     ]
    }
   ],
   "source": [
    "for k, v in states.items():\n",
    "    print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.pretrained_features[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.pretrained_features[0].weight.data = states['model']['Conv_Body.conv1.0.weight']\n",
    "model.pretrained_features[0].bias.data   = states['model']['Conv_Body.conv1.0.bias']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.new_features.conv5_1.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg = torchvision.models.vgg16(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg.features[24].bias == model.new_features.conv5_1.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_in_states(model, states):\n",
    "    model.pretrained_features[0].weight.data = states['features.0.weight']\n",
    "    model.pretrained_features[0].bias.data   = states['features.0.bias']\n",
    "\n",
    "    model.pretrained_features[2].weight.data = states['features.2.weight']\n",
    "    model.pretrained_features[2].bias.data   = states['features.2.bias']\n",
    "\n",
    "    model.pretrained_features[5].weight.data = states['features.5.weight']\n",
    "    model.pretrained_features[5].bias.data   = states['features.5.bias']\n",
    "\n",
    "    model.pretrained_features[7].weight.data = states['features.7.weight']\n",
    "    model.pretrained_features[7].bias.data   = states['features.7.bias']\n",
    "\n",
    "    model.pretrained_features[10].weight.data = states['features.10.weight']\n",
    "    model.pretrained_features[10].bias.data   = states['features.10.bias']\n",
    "\n",
    "    model.pretrained_features[12].weight.data = states['features.12.weight']\n",
    "    model.pretrained_features[12].bias.data   = states['features.12.bias']\n",
    "\n",
    "    model.pretrained_features[14].weight.data = states['features.14.weight']\n",
    "    model.pretrained_features[14].bias.data   = states['features.14.bias']\n",
    "\n",
    "    model.pretrained_features[17].weight.data = states['features.17.weight']\n",
    "    model.pretrained_features[17].bias.data   = states['features.17.bias']\n",
    "\n",
    "    model.pretrained_features[19].weight.data = states['features.19.weight']\n",
    "    model.pretrained_features[19].bias.data   = states['features.19.bias']\n",
    "\n",
    "    model.pretrained_features[21].weight.data = states['features.21.weight']\n",
    "    model.pretrained_features[21].bias.data   = states['features.21.bias']\n",
    "\n",
    "    model.new_features[0].weight.data = states['features.24.weight']\n",
    "    model.new_features[0].bias.data   = states['features.24.bias']\n",
    "\n",
    "    model.new_features[2].weight.data = states['features.26.weight']\n",
    "    model.new_features[2].bias.data   = states['features.26.bias']\n",
    "\n",
    "    model.new_features[4].weight.data = states['features.28.weight']\n",
    "    model.new_features[4].bias.data   = states['features.28.bias']\n",
    "\n",
    "    model.fc67[0].weight.data = states['fcs.0.weight']\n",
    "    model.fc67[0].bias.data   = states['fcs.0.bias']\n",
    "\n",
    "    model.fc67[3].weight.data = states['fcs.3.weight']\n",
    "    model.fc67[3].bias.data   = states['fcs.3.bias']\n",
    "\n",
    "    model.fc8d.weight.data = states['fc_c.weight']\n",
    "    model.fc8d.bias.data   = states['fc_c.bias']\n",
    "\n",
    "    model.fc8c.weight.data = states['fc_d.weight']\n",
    "    model.fc8c.bias.data   = states['fc_d.bias']\n",
    "\n",
    "    model.ic_score1.weight.data = states['fc_ic_score.weight']\n",
    "    model.ic_score1.bias.data   = states['fc_ic_score.bias']\n",
    "\n",
    "    model.ic_score2.weight.data = states['fc_ic_score1.weight']\n",
    "    model.ic_score2.bias.data   = states['fc_ic_score1.bias']\n",
    "\n",
    "    model.ic_score3.weight.data = states['fc_ic_score2.weight']\n",
    "    model.ic_score3.bias.data   = states['fc_ic_score2.bias']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.pretrained_features[0].weight.data = states['features.0.weight']\n",
    "model.pretrained_features[0].bias.data   = states['features.0.bias']\n",
    "\n",
    "model.pretrained_features[2].weight.data = states['features.2.weight']\n",
    "model.pretrained_features[2].bias.data   = states['features.2.bias']\n",
    "\n",
    "model.pretrained_features[5].weight.data = states['features.5.weight']\n",
    "model.pretrained_features[5].bias.data   = states['features.5.bias']\n",
    "\n",
    "model.pretrained_features[7].weight.data = states['features.7.weight']\n",
    "model.pretrained_features[7].bias.data   = states['features.7.bias']\n",
    "\n",
    "model.pretrained_features[10].weight.data = states['features.10.weight']\n",
    "model.pretrained_features[10].bias.data   = states['features.10.bias']\n",
    "\n",
    "model.pretrained_features[12].weight.data = states['features.12.weight']\n",
    "model.pretrained_features[12].bias.data   = states['features.12.bias']\n",
    "\n",
    "model.pretrained_features[14].weight.data = states['features.14.weight']\n",
    "model.pretrained_features[14].bias.data   = states['features.14.bias']\n",
    "\n",
    "model.pretrained_features[17].weight.data = states['features.17.weight']\n",
    "model.pretrained_features[17].bias.data   = states['features.17.bias']\n",
    "\n",
    "model.pretrained_features[19].weight.data = states['features.19.weight']\n",
    "model.pretrained_features[19].bias.data   = states['features.19.bias']\n",
    "\n",
    "model.pretrained_features[21].weight.data = states['features.21.weight']\n",
    "model.pretrained_features[21].bias.data   = states['features.21.bias']\n",
    "\n",
    "model.new_features[0].weight.data = states['features.24.weight']\n",
    "model.new_features[0].bias.data   = states['features.24.bias']\n",
    "\n",
    "model.new_features[2].weight.data = states['features.26.weight']\n",
    "model.new_features[2].bias.data   = states['features.26.bias']\n",
    "\n",
    "model.new_features[4].weight.data = states['features.28.weight']\n",
    "model.new_features[4].bias.data   = states['features.28.bias']\n",
    "\n",
    "model.fc67[0].weight.data = states['fcs.0.weight']\n",
    "model.fc67[0].bias.data   = states['fcs.0.bias']\n",
    "\n",
    "model.fc67[3].weight.data = states['fcs.3.weight']\n",
    "model.fc67[3].bias.data   = states['fcs.3.bias']\n",
    "\n",
    "model.fc8d.weight.data = states['fc_c.weight']\n",
    "model.fc8d.bias.data   = states['fc_c.bias']\n",
    "\n",
    "model.fc8c.weight.data = states['fc_d.weight']\n",
    "model.fc8c.bias.data   = states['fc_d.bias']\n",
    "\n",
    "model.ic_score1.weight.data = states['fc_ic_score.weight']\n",
    "model.ic_score1.bias.data   = states['fc_ic_score.bias']\n",
    "\n",
    "model.ic_score2.weight.data = states['fc_ic_score1.weight']\n",
    "model.ic_score2.bias.data   = states['fc_ic_score1.bias']\n",
    "\n",
    "model.ic_score3.weight.data = states['fc_ic_score2.weight']\n",
    "model.ic_score3.bias.data   = states['fc_ic_score2.bias']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[[[-0.5502,  0.1449,  0.5306],\n",
       "          [-0.5797,  0.3582,  0.7667],\n",
       "          [-0.6870, -0.0460,  0.4855]],\n",
       "\n",
       "         [[ 0.1760,  0.0104, -0.0808],\n",
       "          [ 0.0447, -0.0699, -0.2597],\n",
       "          [ 0.1326, -0.1725, -0.1319]],\n",
       "\n",
       "         [[ 0.3114, -0.1670, -0.4281],\n",
       "          [ 0.4733, -0.0840, -0.4877],\n",
       "          [ 0.6297,  0.0177, -0.2785]]],\n",
       "\n",
       "\n",
       "        [[[ 0.2331,  0.1272,  0.1865],\n",
       "          [-0.4269, -0.2426,  0.2467],\n",
       "          [-0.2499,  0.1421, -0.0047]],\n",
       "\n",
       "         [[-0.1407, -0.2188,  0.1504],\n",
       "          [-0.8404, -0.3513,  0.5636],\n",
       "          [-0.2419,  0.5187,  0.5389]],\n",
       "\n",
       "         [[-0.3139, -0.3699, -0.1305],\n",
       "          [-0.4708, -0.1547,  0.3459],\n",
       "          [ 0.0543,  0.5863,  0.4958]]],\n",
       "\n",
       "\n",
       "        [[[ 0.1773,  0.5212,  0.0102],\n",
       "          [-0.2708, -0.7154,  0.3127],\n",
       "          [-0.0754, -0.2203,  0.3343]],\n",
       "\n",
       "         [[ 0.3078,  0.6690,  0.0198],\n",
       "          [-0.4660, -1.0686,  0.3337],\n",
       "          [-0.0811, -0.3057,  0.5430]],\n",
       "\n",
       "         [[ 0.3144,  0.4219, -0.3500],\n",
       "          [ 0.0857, -0.4644,  0.0110],\n",
       "          [ 0.1039, -0.1464, -0.0164]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[ 0.0791,  0.1281,  0.0341],\n",
       "          [ 0.2224,  0.2477, -0.0446],\n",
       "          [ 0.0481,  0.0299,  0.0195]],\n",
       "\n",
       "         [[-0.1826, -0.0672, -0.0069],\n",
       "          [-0.0487,  0.0069, -0.1284],\n",
       "          [-0.0646, -0.0647,  0.0439]],\n",
       "\n",
       "         [[-0.2244, -0.1187, -0.0229],\n",
       "          [-0.0986, -0.0150,  0.0012],\n",
       "          [-0.0261,  0.0013,  0.1424]]],\n",
       "\n",
       "\n",
       "        [[[ 0.0163, -0.0323, -0.0040],\n",
       "          [-0.0681, -0.1940, -0.1413],\n",
       "          [-0.0694, -0.1830, -0.1738]],\n",
       "\n",
       "         [[ 0.0421, -0.0680, -0.0077],\n",
       "          [ 0.0113, -0.1497, -0.1238],\n",
       "          [ 0.0098, -0.1041, -0.1177]],\n",
       "\n",
       "         [[ 0.1254,  0.0840,  0.1295],\n",
       "          [ 0.1746,  0.1118,  0.1182],\n",
       "          [ 0.1456,  0.0980,  0.1025]]],\n",
       "\n",
       "\n",
       "        [[[ 0.0317, -0.1078, -0.2639],\n",
       "          [ 0.2788, -0.0377, -0.2547],\n",
       "          [ 0.3478,  0.0295, -0.0564]],\n",
       "\n",
       "         [[ 0.2513,  0.1562, -0.1732],\n",
       "          [ 0.3930,  0.0333, -0.3505],\n",
       "          [ 0.1937, -0.1979, -0.2960]],\n",
       "\n",
       "         [[ 0.4602,  0.4340,  0.2837],\n",
       "          [ 0.1637, -0.0574, -0.1910],\n",
       "          [-0.1943, -0.4551, -0.4262]]]], device='cuda:0', requires_grad=True)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.pretrained_features[0].weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sjjPy3",
   "language": "python",
   "name": "sjjpy3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
