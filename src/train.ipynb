{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data\n",
    "import datetime\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from torch import optim\n",
    "from torchvision.ops import roi_pool, nms\n",
    "from sklearn.metrics import average_precision_score\n",
    "from config import cfg\n",
    "from utils import *\n",
    "from models import OICR_Alexnet, OICR_VGG16\n",
    "from refine_loss import WeightedRefineLoss\n",
    "from datasets import VOCDectectionDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "year='2007'\n",
    "pretrained='alexnet'\n",
    "oicr = None\n",
    "if pretrained == 'alexnet':\n",
    "    oicr = OICR_Alexnet()\n",
    "elif pretrained == 'vgg16':\n",
    "    oicr = OICR_VGG16\n",
    "oicr.init_model()\n",
    "oicr.to(cfg.DEVICE)\n",
    "oicr.train()\n",
    "\n",
    "trainval = VOCDectectionDataset(\"~/data/\", year, 'trainval')\n",
    "train_loader = data.DataLoader(trainval, cfg.TRAIN.BATCH_SIZE, shuffle=True)\n",
    "\n",
    "optimizer = optim.SGD(oicr.parameters(),\n",
    "                      lr=cfg.TRAIN.LR,\n",
    "                      weight_decay=cfg.TRAIN.WD,\n",
    "                      momentum=cfg.TRAIN.MOMENTUM)\n",
    "scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=[12, 28], gamma=0.1)\n",
    "log_file = cfg.PATH.LOG_PATH + f\"oicr_{pretrained}_\" + datetime.datetime.now().strftime('%m-%d_%H:%M')+ \".txt\"\n",
    "N = len(train_loader)\n",
    "bceloss = nn.BCELoss(reduction=\"sum\")\n",
    "refineloss = WeightedRefineLoss()\n",
    "# write_log(log_file, f\"model_name: oicr_{pretrained}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c08538c0bcc4d6b8ecca788ebdda80b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Total', max=28.0, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a46f7442695049cb8bed1cc735aae959",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 0', max=5011.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in tqdm(range(cfg.TRAIN.EPOCH_07), \"Total\"):\n",
    "    iter_id = 0 # use to do accumulated gd\n",
    "    epoch_loss = 0.0\n",
    "    for img, gt_box, gt_label, regions in tqdm(train_loader, f\"Epoch {epoch}\"):\n",
    "        img = img.to(cfg.DEVICE)  # 1, 3, h ,w \n",
    "        regions = regions.to(cfg.DEVICE) # 1, R, 4\n",
    "        R = regions.size()[1] # R\n",
    "        gt_label = gt_label.to(cfg.DEVICE) # 1, C\n",
    "        refine_scores = []\n",
    "        \n",
    "        proposal_scores, refine_scores = oicr(img, regions)\n",
    "        \n",
    "        xr0 = torch.zeros((R, 21)).to(cfg.DEVICE) # xj0\n",
    "        xr0[:, :20] = proposal_scores\n",
    "        # R+1 x 21\n",
    "        refine_scores.insert(0, xr0)\n",
    "\n",
    "        cls_scores = torch.sum(proposal_scores, dim=0)\n",
    "        cls_scores = torch.clamp(cls_scores, min=0.0, max=1.0)\n",
    "        b_loss = bceloss(cls_scores, gt_label[0])\n",
    "        r_loss = [None for _ in range(cfg.K)]\n",
    "        \n",
    "        \n",
    "        # then do the online instance classifier refinement\n",
    "        # R x k\n",
    "        wrk_list = torch.Tensor([[0 for _ in range(R)] for _ in range(cfg.K)]).to(cfg.DEVICE)\n",
    "        # R x 21 x k\n",
    "        yrk_list = torch.Tensor([\n",
    "            [[0 for _ in range(1 + len(VOC_CLASSES))]for _ in range(R)]for _ in range(cfg.K)\n",
    "        ])\n",
    "        \n",
    "        yrk_list = yrk_list.to(cfg.DEVICE)\n",
    "        yrk_list[:, :, -1] = 1.0\n",
    "        \n",
    "        for k in range(cfg.K):\n",
    "            IoUs = torch.Tensor([-np.inf for _ in range(R)]).to(cfg.DEVICE)\n",
    "            for c in range(len(VOC_CLASSES)):\n",
    "                if gt_label[0][c] == 1:\n",
    "                    top_id = torch.argmax(refine_scores[k][:, c])\n",
    "                    top_box = regions[0][top_id:top_id+1]\n",
    "                    IoUs_temp = one2allbox_iou(top_box, regions[0])\n",
    "                    IoU_mask = IoUs_temp > IoUs\n",
    "                    IoUs = IoU_mask * IoUs_temp\n",
    "                    wrk_list[k] = IoU_mask * refine_scores[k][top_id][c]\n",
    "                    y_mask = IoUs > cfg.TRAIN.It\n",
    "                    yrk_list[k][y_mask] = 0.0\n",
    "                    yrk_list[k][y_mask] += torch.Tensor([1 if _ == c else 0 for _ in range(21)]).to(cfg.DEVICE)\n",
    "            r_loss[k] = refineloss(refine_scores[k+1], \n",
    "                                   yrk_list[k].clone(),\n",
    "                                   wrk_list[k].clone())\n",
    "        break\n",
    "        loss = b_loss + sum(r_loss)\n",
    "        epoch_loss += loss.item()\n",
    "        loss.backward()\n",
    "        iter_id += 1\n",
    "        if iter_id % cfg.TRAIN.ITER_SIZE == 0 or iter_id == N:\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "    break\n",
    "    print(f\"Epoch {epoch} Loss is {epoch_loss/N}\")\n",
    "    write_log(log_file, f\"Epoch {epoch} Loss is {epoch_loss/N}\")         \n",
    "    scheduler.step()\n",
    "    torch.save({\n",
    "        'epoch' : epoch,\n",
    "        'model_state_dict' : oicr.state_dict(),\n",
    "        'optimizer_state_dict' : optimizer.state_dict(),\n",
    "        'scheduler_state_dict' : scheduler.state_dict(),\n",
    "        'loss': loss\n",
    "        }, SAVE_PATH + f\"oicr_{year}_{pretrained}_Epoch {epoch}.pt\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[6.5627e-05, 7.0005e-05, 6.9187e-05,  ..., 6.7141e-05, 6.3734e-05,\n",
       "         0.0000e+00],\n",
       "        [6.5556e-05, 6.9848e-05, 6.8343e-05,  ..., 6.8204e-05, 6.3444e-05,\n",
       "         0.0000e+00],\n",
       "        [6.5984e-05, 6.9938e-05, 6.8465e-05,  ..., 6.6538e-05, 6.3346e-05,\n",
       "         0.0000e+00],\n",
       "        ...,\n",
       "        [6.5546e-05, 7.1723e-05, 6.8112e-05,  ..., 6.6166e-05, 6.4851e-05,\n",
       "         0.0000e+00],\n",
       "        [6.4393e-05, 6.9242e-05, 7.0843e-05,  ..., 6.4501e-05, 6.5493e-05,\n",
       "         0.0000e+00],\n",
       "        [6.5099e-05, 6.8822e-05, 6.9641e-05,  ..., 6.8245e-05, 6.5426e-05,\n",
       "         0.0000e+00]], grad_fn=<CopySlices>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xr0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([756, 20])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proposal_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\n",
    "    'model_state_dict' : oicr.state_dict(),\n",
    "}, SAVE_PATH + f\"oicr_{year}_{pretrained}_Epoch finished.pt\")\n",
    "write_log(log_file, f\"model file is already saved\")\n",
    "write_log(log_file, f\"training finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0000e+00, 0.0000e+00, 0.0000e+00, 1.3561e-04, 0.0000e+00, 1.4446e-04,\n",
       "        1.2402e-06, 2.0132e-06, 0.0000e+00, 0.0000e+00, 1.9903e-06, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 1.5197e-04, 3.9958e-05, 9.0783e-06,\n",
       "        0.0000e+00, 0.0000e+00], device='cuda:0', grad_fn=<ClampBackward>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cls_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WeightedRefineLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(WeightedRefineLoss, self).__init__()\n",
    "        \n",
    "    def forward(self, refine_scores, refine_y, weights):\n",
    "        R, C = refine_scores.size()\n",
    "        if refine_scores.size() != refine_y.size():\n",
    "            assert ValueError(\"scores have different size from y\")\n",
    "        if weights.size() != R:\n",
    "            assert ValueError(\"weights's length is wrong\")\n",
    "        ylogx = torch.log(refine_scores) * refine_y\n",
    "        ylogx_all_cls = torch.sum(ylogx, dim=1)\n",
    "        loss = torch.sum(w * ylogx_all_cls) * -1 / R\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sjjPy3",
   "language": "python",
   "name": "sjjpy3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
