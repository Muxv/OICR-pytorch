{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data\n",
    "import datetime\n",
    "\n",
    "from tensorboardX import SummaryWriter\n",
    "from tqdm.notebook import tqdm\n",
    "from torch import optim\n",
    "from torchvision.ops import roi_pool, nms\n",
    "from sklearn.metrics import average_precision_score\n",
    "from config import cfg\n",
    "from utils import *\n",
    "from models import OICR, MIDN_Alexnet, MIDN_VGG16\n",
    "from refine_loss import WeightedRefineLoss\n",
    "from datasets import VOCDectectionDataset\n",
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter(\"../boardX\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../checkpoints/Model_2007_alexnet_Epoch finished.pt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-c87d237a0947>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcheck_points\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0mcheckpoints\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPATH\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPT_PATH\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"Model_2007_alexnet_Epoch finished.pt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0mstart_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mmidn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoints\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'midn_model_state_dict'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/sjjPy3/lib/python3.8/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    523\u001b[0m         \u001b[0mpickle_load_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'encoding'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 525\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    526\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_is_zipfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0m_open_zipfile_reader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/sjjPy3/lib/python3.8/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 212\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    213\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'w'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/sjjPy3/lib/python3.8/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_open_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../checkpoints/Model_2007_alexnet_Epoch finished.pt'"
     ]
    }
   ],
   "source": [
    "year='2007'\n",
    "pretrained='alexnet'\n",
    "oicr = None\n",
    "midn = None\n",
    "check_points = True\n",
    "start_epoch = 0\n",
    "\n",
    "if pretrained == 'alexnet':\n",
    "    midn = MIDN_Alexnet()\n",
    "elif pretrained == 'vgg16':\n",
    "    midn = MIDN_VGG16()\n",
    "midn.init_model()\n",
    "midn.to(cfg.DEVICE)\n",
    "\n",
    "oicr = OICR(cfg.K)\n",
    "oicr.init_model()\n",
    "oicr.to(cfg.DEVICE)\n",
    "\n",
    "if check_points:\n",
    "    checkpoints = torch.load(cfg.PATH.PT_PATH + \"Model_2007_alexnet_Epoch finished.pt\")\n",
    "\n",
    "    midn.load_state_dict(checkpoints['midn_model_state_dict'])\n",
    "    oicr.init_model()\n",
    "\n",
    "trainval = VOCDectectionDataset(\"~/data/\", year, 'trainval')\n",
    "train_loader = data.DataLoader(trainval, cfg.TRAIN.BATCH_SIZE, shuffle=False)\n",
    "\n",
    "midn_optimizer = optim.Adam(midn.parameters(),\n",
    "                           lr=cfg.TRAIN.LR,\n",
    "                           weight_decay=cfg.TRAIN.WD)\n",
    "scheduler = optim.lr_scheduler.MultiStepLR(midn_optimizer,\n",
    "                                           milestones=[cfg.TRAIN.LR_STEP,\n",
    "                                                       cfg.TRAIN.EPOCH],\n",
    "                                           gamma=cfg.TRAIN.LR_MUL)\n",
    "oicr_optimizer = optim.Adam(oicr.parameters(),\n",
    "                            lr=0.1*cfg.TRAIN.LR,\n",
    "                            weight_decay=cfg.TRAIN.WD)\n",
    "\n",
    "log_file = cfg.PATH.LOG_PATH + f\"oicr_{pretrained}_\" + datetime.datetime.now().strftime('%m-%d_%H:%M')+ \".txt\"\n",
    "N = len(train_loader)\n",
    "bceloss = nn.BCELoss(reduction=\"sum\")\n",
    "refineloss = WeightedRefineLoss()\n",
    "\n",
    "    \n",
    "\n",
    "midn.train()\n",
    "oicr.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def oicr_algorithm(refined_scores, gt_label, regions, K=3):\n",
    "    R = regions.size()[1] # R\n",
    "    # then do the online instance classifier refinement\n",
    "    wrk_list = torch.zeros((K, R)).to(cfg.DEVICE)\n",
    "    # R x 21 x k\n",
    "    yrk_list = torch.zeros((K, R, (1 + len(VOC_CLASSES))))\n",
    "    yrk_list[:, :, -1] = 1.0\n",
    "    yrk_list = yrk_list.to(cfg.DEVICE)\n",
    "#     # here is just to calculate the supervised information \n",
    "#     # do not need grad any more\n",
    "    with torch.no_grad():\n",
    "        for k in range(K):\n",
    "            wrk = wrk_list[k, :]\n",
    "            yrk = yrk_list[k, :, :]\n",
    "            IoUs = torch.full((R, ), - np.inf).to(cfg.DEVICE)\n",
    "            for c in range(len(VOC_CLASSES)):\n",
    "                if gt_label[0][c] == 1.0:\n",
    "                    top_id = torch.argmax(refine_scores[k][:, c])\n",
    "                    top_box = regions[0][top_id:top_id+1]\n",
    "                    IoUs_temp = one2allbox_iou(top_box, regions[0])\n",
    "                    IoU_mask = torch.where(IoUs_temp > IoUs)\n",
    "                    IoUs[IoU_mask] = IoUs_temp[IoU_mask]\n",
    "                    wrk[IoU_mask] = refine_scores[k][top_id][c]\n",
    "                    y_mask = torch.where(IoUs > cfg.TRAIN.It)\n",
    "                    yrk[y_mask] = 0.0\n",
    "                    yrk[y_mask] += torch.eye(1 + len(VOC_CLASSES))[c].to(cfg.DEVICE)\n",
    "    return wrk_list, yrk_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9840de26e00d402c9a28c15e74c5b342",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Total', max=11.0, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "596163a33a374dbfab612d2299073bb9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 10', max=5011.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 10 b_Loss is 0.0\n",
      "Epoch 10 r_Loss is 0.3184112033970434\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc77d4109e3f435fb9283306fa80f5f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 11', max=5011.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img_num = 0\n",
    "for epoch in tqdm(range(start_epoch, cfg.TRAIN.EPOCH + 1), \"Total\"):\n",
    "#     img_num = 0\n",
    "    iter_id = 0 # use to do accumulated gd\n",
    "    epoch_b_loss = 0.0\n",
    "    epoch_r_loss = 0.0\n",
    "    for img, gt_box, gt_label, regions in tqdm(train_loader, f\"Epoch {epoch}\"):\n",
    "        \n",
    "        img = img.to(cfg.DEVICE)  # 1, 3, h ,w \n",
    "        regions = regions.to(cfg.DEVICE) # 1, R, 4\n",
    "        R = regions.size()[1] # R\n",
    "        gt_label = gt_label.to(cfg.DEVICE) # 1, C\n",
    "\n",
    "        with torch.no_grad():\n",
    "            fc7, proposal_scores = midn(img, regions)\n",
    "            cls_scores = torch.sum(proposal_scores, dim=0)\n",
    "            cls_scores = torch.clamp(cls_scores, min=0.0, max=1.0)\n",
    "            b_loss = bceloss(cls_scores, gt_label[0])\n",
    "        if epoch < 10:\n",
    "            b_loss.backward()\n",
    "            epoch_b_loss += b_loss.item()\n",
    "\n",
    "        else:\n",
    "            refine_scores = oicr(fc7.detach())\n",
    "            xr0 = torch.zeros((R, 21)).to(cfg.DEVICE) # xj0\n",
    "            xr0[:, :20] = proposal_scores.detach()\n",
    "            # R+1 x 21\n",
    "            refine_scores.insert(0, xr0)\n",
    "\n",
    "            r_loss = [None for _ in range(cfg.K)]\n",
    "            wrk_list, yrk_list = oicr_algorithm(refine_scores, gt_label, regions, cfg.K)\n",
    "            for k in range(cfg.K):\n",
    "                r_loss[k] = refineloss(refine_scores[k+1], \n",
    "                                       yrk_list[k],\n",
    "                                       wrk_list[k])\n",
    "            writer.add_histogram(\"rscore1\", refine_scores[1].cpu().detach().numpy(), img_num)\n",
    "   \n",
    "#             b_loss.backward()\n",
    "            sum(r_loss).backward()\n",
    "#             epoch_b_loss += b_loss.item()\n",
    "            writer.add_scalar(\"r_loss\", sum(r_loss).item(), img_num)\n",
    "\n",
    "            epoch_r_loss += sum(r_loss).item()\n",
    "        img_num += 1\n",
    "        iter_id += 1\n",
    "        if iter_id % cfg.TRAIN.ITER_SIZE == 0 or iter_id == N:\n",
    "#             midn_optimizer.step()\n",
    "#             midn_optimizer.zero_grad()\n",
    "            if epoch >= 10:\n",
    "                writer.add_histogram(\"refine_3w\", oicr.refine2.ic_score0.weight.clone().cpu().data.numpy(), img_num)\n",
    "                writer.add_histogram(\"refine_3b\", oicr.refine2.ic_score0.bias.clone().cpu().data.numpy(), img_num)\n",
    "                writer.add_histogram(\"refine_3w grad\", oicr.refine2.ic_score0.weight.grad.clone().cpu().data.numpy(), img_num)\n",
    "                writer.add_histogram(\"refine_3b grad\", oicr.refine2.ic_score0.bias.grad.clone().cpu().data.numpy(), img_num)\n",
    "   \n",
    "                oicr_optimizer.step()\n",
    "                oicr_optimizer.zero_grad()\n",
    "\n",
    "    if epoch < 10:\n",
    "        print(f\"Epoch {epoch} b_Loss is {epoch_b_loss/N}\")\n",
    "#         write_log(log_file, f\"Epoch {epoch} b_Loss is {epoch_b_loss/N}\")\n",
    "    else:\n",
    "        print(f\"Epoch {epoch} b_Loss is {epoch_b_loss/N}\")\n",
    "#         write_log(log_file, f\"Epoch {epoch} b_Loss is {epoch_b_loss/N}\") \n",
    "        print(f\"Epoch {epoch} r_Loss is {epoch_r_loss/N}\")\n",
    "#         write_log(log_file, f\"Epoch {epoch} r_Loss is {epoch_r_loss/N}\")\n",
    "#     break\n",
    "    \n",
    "#     scheduler.step()\n",
    "    torch.save({\n",
    "        'epoch' : epoch,\n",
    "        'oicr_model_state_dict' : oicr.state_dict(),\n",
    "        'oicr_optimizer_state_dict' : oicr_optimizer.state_dict(),\n",
    "        'r_loss': r_loss\n",
    "        }, cfg.PATH.PT_PATH + f\"OICR_{year}_{pretrained}_Epoch {epoch}.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(141, device='cuda:0')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_id = torch.argmax(refine_scores[k][:, c])\n",
    "top_box = regions[0][top_id:top_id+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "oicr.refine0.ic_score0.weight.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
