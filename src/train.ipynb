{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data\n",
    "import datetime\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from torch import optim\n",
    "from torchvision.ops import roi_pool, nms\n",
    "from sklearn.metrics import average_precision_score\n",
    "from config import cfg\n",
    "from utils import *\n",
    "from models import *\n",
    "from refine_loss import WeightedRefineLoss\n",
    "from datasets import VOCDectectionDataset\n",
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "\n",
    "import pyximport\n",
    "import numpy as np\n",
    "pyximport.install(setup_args={\"include_dirs\":np.get_include()},\n",
    "                  reload_support=True)\n",
    "import torch\n",
    "import pdb\n",
    "from bbox import bbox_overlaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "year='2007'\n",
    "pretrained='vgg16'\n",
    "oicr = None\n",
    "midn = None\n",
    "check_points = True\n",
    "\n",
    "eva_th = 1\n",
    "lr = 1e-4\n",
    "lr_step = 5\n",
    "epochs = 5\n",
    "# start_epoch = 29\n",
    "start_epoch = 0\n",
    "\n",
    "if pretrained == 'alexnet':\n",
    "    model = Combined_Alexnet(cfg.K, cfg.Groups)\n",
    "if pretrained == 'vgg16':\n",
    "    model = Combined_VGG16(cfg.K)\n",
    "\n",
    "model.init_model()\n",
    "model.to(cfg.DEVICE)\n",
    "\n",
    "checkpoints = torch.load(cfg.PATH.PT_PATH + \"BestModel_2007_vgg16_23.pt\")\n",
    "model.load_state_dict(checkpoints['whole_model_state_dict'])\n",
    "\n",
    "trainval = VOCDectectionDataset(\"~/data/\", year, 'trainval')\n",
    "train_loader = data.DataLoader(trainval, cfg.TRAIN.BATCH_SIZE, shuffle=False)\n",
    "testdata = VOCDectectionDataset(\"~/data/\", year, 'test')\n",
    "test_loader = data.DataLoader(testdata, 1, shuffle=False)\n",
    "\n",
    "\n",
    "bias_params = []\n",
    "bias_param_names = []\n",
    "nonbias_params = []\n",
    "nonbias_param_names = []\n",
    "nograd_param_names = []\n",
    "for key, value in model.named_parameters():\n",
    "    if value.requires_grad:\n",
    "        if 'bias' in key:\n",
    "            bias_params.append(value)\n",
    "            bias_param_names.append(key)\n",
    "        else:\n",
    "            nonbias_params.append(value)\n",
    "            nonbias_param_names.append(key)\n",
    "            \n",
    "params = [\n",
    "    {'params': nonbias_params,\n",
    "     'lr': lr,\n",
    "     'weight_decay': cfg.TRAIN.WD},\n",
    "    {'params': bias_params,\n",
    "     'lr': lr * (cfg.TRAIN.BIAS_DOUBLE_LR + 1),\n",
    "     'weight_decay':  0},\n",
    "]\n",
    "\n",
    "optimizer = optim.SGD(params,\n",
    "                      momentum=cfg.TRAIN.MOMENTUM)\n",
    "\n",
    "#   scheduler = optim.lr_scheduler.MultiStepLR(optimizer,\n",
    "#                                              milestones=[lr_step,\n",
    "#                                                          epochs],\n",
    "#                                              gamma=cfg.TRAIN.LR_MUL)\n",
    "mAP = 0\n",
    "best_mAP = 0\n",
    "best_model = None\n",
    "best_epoch = 0\n",
    "\n",
    "N = len(train_loader)\n",
    "bceloss = nn.BCELoss(reduction=\"sum\")\n",
    "refineloss = WeightedRefineLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def oicr_algorithm(xrk_list, gt_label, regions, K=3):\n",
    "    R = regions.size()[1] # R\n",
    "    # then do the online instance classifier refinement\n",
    "    wrk_list = torch.zeros((K, R)).to(cfg.DEVICE)\n",
    "    # R x 21 x k\n",
    "    yrk_list = torch.zeros((K, R, (1 + len(VOC_CLASSES))))\n",
    "    yrk_list[:, :, -1] = 1.0\n",
    "    yrk_list = yrk_list.to(cfg.DEVICE)\n",
    "#     # here is just to calculate the supervised information \n",
    "#     # do not need grad any more\n",
    "    with torch.no_grad():\n",
    "        for k in range(K):\n",
    "            wrk = wrk_list[k, :]\n",
    "            yrk = yrk_list[k, :, :]\n",
    "            IoUs = torch.full((R, ), - np.inf).to(cfg.DEVICE)\n",
    "            for c in range(len(VOC_CLASSES)):\n",
    "                if gt_label[0][c] == 1.0:\n",
    "                    top_id = torch.argmax(xrk_list[k][:, c])\n",
    "                    top_score = xrk_list[k][top_id][c]\n",
    "#                     writer.add_scalar(\"top_score\", top_score, 0)\n",
    "#                     print(top_score)\n",
    "                    top_box = regions[0][top_id:top_id+1]\n",
    "                    IoUs_temp = one2allbox_iou(top_box, regions[0])\n",
    "                    IoU_mask = torch.where(IoUs_temp > IoUs)\n",
    "                    IoUs[IoU_mask] = IoUs_temp[IoU_mask]\n",
    "                    wrk[IoU_mask] = top_score\n",
    "                    y_mask = torch.where(IoUs[IoU_mask] > cfg.TRAIN.It)\n",
    "                    yrk[y_mask] = 0.0\n",
    "                    yrk[y_mask] += torch.eye(1 + len(VOC_CLASSES))[c].to(cfg.DEVICE)\n",
    "    return wrk_list, yrk_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def OICRLayer(boxes, cls_prob, im_labels, cfg_TRAIN_FG_THRESH = 0.5):\n",
    "    # boxes = boxes[...,1:]\n",
    "    # boxes:[1, 3189, 4]\n",
    "    # 上一层传来的cls_prob:[1, 3819, 20/21]\n",
    "    # image level label -> im_labels:[1, 20]\n",
    "    proposals = _get_highest_score_proposals(boxes, cls_prob, im_labels)\n",
    "    labels, cls_loss_weights = _sample_rois(boxes, proposals, 21)\n",
    "    return labels, cls_loss_weights\n",
    "\n",
    "def _get_highest_score_proposals(boxes, cls_prob, im_labels):\n",
    "    \"\"\"Get proposals with highest score.\"\"\"\n",
    "\n",
    "    num_images, num_classes = im_labels.shape\n",
    "    assert num_images == 1, 'batch size shoud be equal to 1'\n",
    "    # 图片labels\n",
    "    im_labels_tmp = im_labels[0, :]\n",
    "    gt_boxes = np.zeros((0, 4), dtype=np.float32)\n",
    "    gt_classes = np.zeros((0, 1), dtype=np.int32)\n",
    "    gt_scores = np.zeros((0, 1), dtype=np.float32)\n",
    "\n",
    "        # 裁剪掉背景分类\n",
    "    if 21 == cls_prob.shape[2] : # added 1016\n",
    "        cls_prob = cls_prob[:, :, :-1]\n",
    "\n",
    "    # 统计GT类得分最高的box\n",
    "    for i in range(num_classes):\n",
    "        if im_labels_tmp[i] == 1:\n",
    "            print(i)\n",
    "            cls_prob_tmp = cls_prob[:,:, i].data.cpu()\n",
    "            \n",
    "            max_index = np.argmax(cls_prob_tmp)\n",
    "            print(max_index)\n",
    "            # m = boxes[:,max_index, :].reshape(1, -1).cpu()\n",
    "            gt_boxes = np.vstack((gt_boxes, boxes[:,max_index, :].reshape(1, -1).cpu()))\n",
    "            gt_classes = np.vstack((gt_classes, (i + 1) * np.ones((1, 1), dtype=np.int32))) # for pushing ground\n",
    "            gt_scores = np.vstack((gt_scores,\n",
    "                cls_prob_tmp[:, max_index] ))  # * np.ones((1, 1), dtype=np.float32)))\n",
    "            cls_prob[:, max_index, :] = 0 #in-place operation <- OICR code but I do not agree\n",
    "    # proposals {[1, 4], [1, 1], [1, 1]}\n",
    "    proposals = {'gt_boxes' : gt_boxes,\n",
    "                 'gt_classes': gt_classes,\n",
    "                 'gt_scores': gt_scores}\n",
    "    return proposals\n",
    "\n",
    "\n",
    "def _sample_rois(all_rois, proposals, num_classes):\n",
    "    \"\"\"Generate a random sample of RoIs comprising foreground and background\n",
    "    examples.\n",
    "    \"\"\"\n",
    "    # overlaps: (rois x gt_boxes)\n",
    "    gt_boxes = proposals['gt_boxes']\n",
    "    gt_labels = proposals['gt_classes']\n",
    "    gt_scores = proposals['gt_scores']\n",
    "    overlaps = bbox_overlaps(\n",
    "        np.ascontiguousarray(all_rois[0].cpu(), dtype=np.float),\n",
    "        np.ascontiguousarray(gt_boxes, dtype=np.float))\n",
    "    try :\n",
    "        gt_assignment = overlaps.argmax(axis=1)\n",
    "        max_overlaps = overlaps.max(axis=1)\n",
    "    except :\n",
    "        pdb.set_trace()\n",
    "\n",
    "    labels = gt_labels[gt_assignment, 0]\n",
    "    cls_loss_weights = gt_scores[gt_assignment, 0]\n",
    "    # Select foreground RoIs as those with >= FG_THRESH overlap\n",
    "    fg_inds = np.where(max_overlaps >= 0.5)[0]\n",
    "\n",
    "    # Select background RoIs as those within [BG_THRESH_LO, BG_THRESH_HI)\n",
    "    bg_inds = np.where(max_overlaps < 0.5)[0]\n",
    "\n",
    "    labels[bg_inds] = 0\n",
    "    real_labels = np.zeros((labels.shape[0], 21))\n",
    "    for i in range(labels.shape[0]) :\n",
    "        real_labels[i, labels[i]] = 1\n",
    "    rois = all_rois.cpu()\n",
    "    return real_labels, cls_loss_weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total:   0%|          | 0/6 [00:00<?, ?it/s]\n",
      "Epoch 0:   0%|          | 0/5011 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 0:   0%|          | 1/5011 [00:00<37:42,  2.21it/s]\u001b[A\n",
      "Epoch 0:   0%|          | 2/5011 [00:01<42:16,  1.98it/s]\u001b[A\n",
      "Epoch 0:   0%|          | 3/5011 [00:01<48:38,  1.72it/s]\u001b[A\n",
      "Epoch 0:   0%|          | 4/5011 [00:03<1:03:06,  1.32it/s]A\n",
      "Total:   0%|          | 0/6 [00:03<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "iter_id = 0\n",
    "\n",
    "for epoch in tqdm(range(start_epoch, epochs+1), \"Total\"):\n",
    "    epoch_b_loss = 0.0\n",
    "    epoch_r_loss = 0.0\n",
    "    for img, gt_box, gt_label, regions in tqdm(train_loader, f\"Epoch {epoch}\"):\n",
    "        img = img.to(cfg.DEVICE)  # 1, 3, h ,w \n",
    "        regions = regions.to(cfg.DEVICE) # 1, R, 4\n",
    "        R = regions.size()[1] # R\n",
    "        gt_label = gt_label.to(cfg.DEVICE) # 1, C\n",
    "\n",
    "        ref_scores1, ref_scores2, ref_scores3, proposal_scores = model(img, regions)\n",
    "        cls_scores = torch.sum(proposal_scores, dim=0)\n",
    "        cls_scores = torch.clamp(cls_scores, min=0, max=1)\n",
    "        \n",
    "        b_loss = bceloss(cls_scores, gt_label[0])\n",
    "        epoch_b_loss += b_loss.item()\n",
    "\n",
    "\n",
    "        xr0 = torch.zeros((R, 21)).to(cfg.DEVICE) # xj0\n",
    "        xr0[:, :20] = proposal_scores.clone()\n",
    "            # R+1 x 21\n",
    "        xrk_list = []\n",
    "        xrk_list.append(xr0)\n",
    "        xrk_list.append(ref_scores1.clone())\n",
    "        xrk_list.append(ref_scores2.clone())\n",
    "        \n",
    "        wrk_list, yrk_list = oicr_algorithm(xrk_list, gt_label, regions, cfg.K)\n",
    "\n",
    "\n",
    "        r_loss_1 = refineloss(ref_scores1, \n",
    "                              yrk_list[0],\n",
    "                              wrk_list[0])\n",
    "        r_loss_2 = refineloss(ref_scores2, \n",
    "                              yrk_list[1],\n",
    "                              wrk_list[1])\n",
    "        r_loss_3 = refineloss(ref_scores3, \n",
    "                              yrk_list[2],\n",
    "                              wrk_list[2])\n",
    "\n",
    "        loss = b_loss + r_loss_1 + r_loss_2 + r_loss_3\n",
    "        loss.backward()\n",
    "        epoch_r_loss += (r_loss_1 + r_loss_2 + r_loss_3).item()\n",
    "\n",
    "        iter_id += 1\n",
    "        if iter_id % cfg.TRAIN.ITER_SIZE == 0:\n",
    "            optimizer.step()\n",
    "#             if iter_id == 2:\n",
    "#                 break\n",
    "            optimizer.zero_grad()\n",
    "        if iter_id == 5:\n",
    "            break\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Combined_VGG16(cfg.K)\n",
    "year=2007\n",
    "\n",
    "model.init_model()\n",
    "model.to(cfg.DEVICE)\n",
    "\n",
    "checkpoints = torch.load(cfg.PATH.PT_PATH + \"BestModel_2007_vgg16_23.pt\")\n",
    "model.load_state_dict(checkpoints['whole_model_state_dict'])\n",
    "\n",
    "trainval = VOCDectectionDataset(\"~/data/\", year, 'trainval', over_box=False, small_box=False)\n",
    "trainval_over = VOCDectectionDataset(\"~/data/\", year, 'trainval', over_box=True, small_box=False)\n",
    "trainval_all = VOCDectectionDataset(\"~/data/\", year, 'trainval', over_box=True, small_box=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index 1: Item 1.0\n"
     ]
    }
   ],
   "source": [
    "print_item(gt_label.squeeze(0).cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0.]], device='cuda:0')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "....................\n",
      "img No.1\n",
      "Index 6: Item 11\n",
      "Index 6: Item 11\n",
      "Index 6: Item 11\n",
      "All box is 33\n",
      "\n",
      "\n",
      "Index 6: Item 18\n",
      "Index 6: Item 14\n",
      "Index 6: Item 18\n",
      "All box is 50\n",
      "\n",
      "\n",
      "Index 6: Item 19\n",
      "Index 6: Item 29\n",
      "Index 6: Item 18\n",
      "All box is 66\n",
      "\n",
      "\n",
      "....................\n",
      "img No.5\n",
      "Index 12: Item 32\n",
      "Index 14: Item 9\n",
      "Index 12: Item 22\n",
      "Index 14: Item 4\n",
      "Index 12: Item 23\n",
      "Index 14: Item 10\n",
      "All box is 100\n",
      "\n",
      "\n",
      "Index 12: Item 50\n",
      "Index 14: Item 18\n",
      "Index 12: Item 41\n",
      "Index 14: Item 4\n",
      "Index 12: Item 41\n",
      "Index 14: Item 11\n",
      "All box is 165\n",
      "\n",
      "\n",
      "Index 12: Item 49\n",
      "Index 14: Item 16\n",
      "Index 12: Item 47\n",
      "Index 14: Item 1\n",
      "Index 12: Item 51\n",
      "Index 14: Item 12\n",
      "All box is 176\n",
      "\n",
      "\n",
      "....................\n",
      "img No.9\n",
      "Index 1: Item 6\n",
      "Index 14: Item 21\n",
      "Index 1: Item 13\n",
      "Index 14: Item 22\n",
      "Index 1: Item 3\n",
      "Index 14: Item 18\n",
      "All box is 83\n",
      "\n",
      "\n",
      "Index 1: Item 34\n",
      "Index 14: Item 23\n",
      "Index 1: Item 29\n",
      "Index 14: Item 30\n",
      "Index 1: Item 36\n",
      "Index 14: Item 26\n",
      "All box is 178\n",
      "\n",
      "\n",
      "Index 1: Item 17\n",
      "Index 14: Item 29\n",
      "Index 1: Item 19\n",
      "Index 14: Item 25\n",
      "Index 1: Item 25\n",
      "Index 14: Item 26\n",
      "All box is 141\n",
      "\n",
      "\n",
      "....................\n",
      "img No.13\n",
      "Index 0: Item 7\n",
      "Index 14: Item 9\n",
      "Index 0: Item 10\n",
      "Index 14: Item 9\n",
      "Index 0: Item 10\n",
      "Index 14: Item 9\n",
      "All box is 54\n",
      "\n",
      "\n",
      "Index 0: Item 38\n",
      "Index 14: Item 10\n",
      "Index 0: Item 39\n",
      "Index 14: Item 6\n",
      "Index 0: Item 19\n",
      "Index 14: Item 4\n",
      "All box is 116\n",
      "\n",
      "\n",
      "Index 0: Item 31\n",
      "Index 14: Item 13\n",
      "Index 0: Item 21\n",
      "Index 14: Item 12\n",
      "Index 0: Item 35\n",
      "Index 14: Item 16\n",
      "All box is 128\n",
      "\n",
      "\n",
      "....................\n",
      "img No.17\n",
      "Index 11: Item 20\n",
      "Index 11: Item 17\n",
      "Index 11: Item 13\n",
      "All box is 50\n",
      "\n",
      "\n",
      "Index 11: Item 24\n",
      "Index 11: Item 27\n",
      "Index 11: Item 26\n",
      "All box is 77\n",
      "\n",
      "\n",
      "Index 11: Item 32\n",
      "Index 11: Item 34\n",
      "Index 11: Item 25\n",
      "All box is 91\n",
      "\n",
      "\n",
      "....................\n",
      "img No.21\n",
      "Index 7: Item 9\n",
      "Index 8: Item 4\n",
      "Index 7: Item 9\n",
      "Index 8: Item 1\n",
      "Index 7: Item 11\n",
      "Index 8: Item 4\n",
      "All box is 38\n",
      "\n",
      "\n",
      "Index 7: Item 22\n",
      "Index 8: Item 2\n",
      "Index 7: Item 7\n",
      "Index 8: Item 8\n",
      "Index 7: Item 21\n",
      "Index 8: Item 8\n",
      "All box is 68\n",
      "\n",
      "\n",
      "Index 7: Item 4\n",
      "Index 8: Item 11\n",
      "Index 7: Item 29\n",
      "Index 8: Item 11\n",
      "Index 7: Item 19\n",
      "Index 8: Item 1\n",
      "All box is 75\n",
      "\n",
      "\n",
      "....................\n",
      "img No.25\n",
      "Index 4: Item 2\n",
      "Index 14: Item 8\n",
      "Index 4: Item 2\n",
      "Index 14: Item 16\n",
      "Index 4: Item 4\n",
      "Index 14: Item 15\n",
      "All box is 47\n",
      "\n",
      "\n",
      "Index 4: Item 5\n",
      "Index 14: Item 9\n",
      "Index 4: Item 4\n",
      "Index 14: Item 27\n",
      "Index 4: Item 12\n",
      "Index 14: Item 22\n",
      "All box is 79\n",
      "\n",
      "\n",
      "Index 4: Item 8\n",
      "Index 14: Item 22\n",
      "Index 4: Item 9\n",
      "Index 14: Item 2\n",
      "Index 4: Item 12\n",
      "Index 14: Item 24\n",
      "All box is 77\n",
      "\n",
      "\n",
      "....................\n",
      "img No.29\n",
      "Index 3: Item 5\n",
      "Index 3: Item 5\n",
      "Index 3: Item 5\n",
      "All box is 15\n",
      "\n",
      "\n",
      "Index 3: Item 11\n",
      "Index 3: Item 11\n",
      "Index 3: Item 10\n",
      "All box is 32\n",
      "\n",
      "\n",
      "Index 3: Item 11\n",
      "Index 3: Item 11\n",
      "Index 3: Item 17\n",
      "All box is 39\n",
      "\n",
      "\n",
      "....................\n",
      "img No.33\n",
      "Index 14: Item 4\n",
      "Index 14: Item 3\n",
      "Index 14: Item 28\n",
      "All box is 35\n",
      "\n",
      "\n",
      "Index 14: Item 14\n",
      "Index 14: Item 11\n",
      "Index 14: Item 39\n",
      "All box is 64\n",
      "\n",
      "\n",
      "Index 14: Item 15\n",
      "Index 14: Item 4\n",
      "Index 14: Item 8\n",
      "All box is 27\n",
      "\n",
      "\n",
      "....................\n",
      "img No.37\n",
      "Index 11: Item 17\n",
      "Index 11: Item 25\n",
      "Index 11: Item 20\n",
      "All box is 62\n",
      "\n",
      "\n",
      "Index 11: Item 7\n",
      "Index 11: Item 37\n",
      "Index 11: Item 24\n",
      "All box is 68\n",
      "\n",
      "\n",
      "Index 11: Item 34\n",
      "Index 11: Item 36\n",
      "Index 11: Item 37\n",
      "All box is 107\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    for i in range(1, 40, 4):\n",
    "        print('.' * 20)\n",
    "        print(f\"img No.{i}\")\n",
    "        for data in [trainval, trainval_over, trainval_all]:\n",
    "            img, gt_box, gt_label, regions = data[i]\n",
    "            img = torch.Tensor(img).to(cfg.DEVICE)  # 1, 3, h ,w \n",
    "            img = img.resize(1, *img.size())\n",
    "            regions = torch.Tensor(regions).to(cfg.DEVICE) # 1, R, 4\n",
    "            regions = regions.resize(1, *regions.size())\n",
    "            R = regions.size()[1] # R\n",
    "            gt_label = torch.Tensor(gt_label).to(cfg.DEVICE) # 1, C\n",
    "            gt_label = gt_label.resize(1, *gt_label.size())\n",
    "\n",
    "            ref_scores1, ref_scores2, ref_scores3, proposal_scores = model(img, regions)\n",
    "\n",
    "            xr0 = torch.zeros((R, 21)).to(cfg.DEVICE) # xj0\n",
    "            xr0[:, :20] = proposal_scores.clone()\n",
    "                # R+1 x 21\n",
    "            xrk_list = []\n",
    "            xrk_list.append(xr0)\n",
    "            xrk_list.append(ref_scores1.clone())\n",
    "            xrk_list.append(ref_scores2.clone())\n",
    "\n",
    "            wrk_list, yrk_list = oicr_algorithm(xrk_list, gt_label, regions, cfg.K)\n",
    "            y1, y2, y3 = yrk_list\n",
    "\n",
    "\n",
    "#             print_item(gt_label.squeeze(0).cpu())\n",
    "            s1 = print_item(y1.sum(dim=0))\n",
    "            s2 = print_item(y2.sum(dim=0))\n",
    "            s3 = print_item(y3.sum(dim=0))\n",
    "            print(f'All box is {s1 + s2 + s3}')\n",
    "            print('\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_item(l):\n",
    "    s = 0\n",
    "    for i in range(len(l)):\n",
    "        if l[i] == 0:\n",
    "            continue\n",
    "        elif i != 20:\n",
    "            print(f\"Index {i}: Item {int(l[i])}\")\n",
    "            s += int(l[i])\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrk_list, yrk_list = oicr_algorithm(xrk_list, gt_label, regions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "tensor(477)\n",
      "1\n",
      "tensor(313)\n",
      "1\n",
      "tensor(313)\n"
     ]
    }
   ],
   "source": [
    "# proposal_scores =  proposal_scores.view(1, -1, R)\n",
    "y1, w1 = OICRLayer(regions, proposal_scores.clone().view(1, R, -1), gt_label)\n",
    "y2, w2 = OICRLayer(regions, ref_scores1.clone().view(1, R, -1), gt_label)\n",
    "y3, w3 = OICRLayer(regions, ref_scores2.clone().view(1, R, -1), gt_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 30,  34, 336, 441, 475, 476, 477, 485]),\n",
       " array([1, 1, 1, 1, 1, 1, 1, 1]))"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(y1[:, 1:] == 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0.]], device='cuda:0')"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0005, device='cuda:0', grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proposal_scores[:, 1][30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([203.,   5., 572., 608.], device='cuda:0')"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regions[0][30, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1089"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wrk_list[1].numel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total:   0%|          | 0/6 [00:00<?, ?it/s]\n",
      "Epoch 0:   0%|          | 0/5011 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 0:   0%|          | 1/5011 [00:00<1:05:20,  1.28it/s]\u001b[A\n",
      "Epoch 0:   0%|          | 2/5011 [00:01<1:01:41,  1.35it/s]\u001b[A\n",
      "Epoch 0:   0%|          | 3/5011 [00:01<53:48,  1.55it/s]  \u001b[A\n",
      "Epoch 0:   0%|          | 4/5011 [00:02<58:36,  1.42it/s]\u001b[A\n",
      "Epoch 0:   0%|          | 5/5011 [00:03<56:13,  1.48it/s]\u001b[A\n",
      "Epoch 0:   0%|          | 6/5011 [00:03<50:32,  1.65it/s]\u001b[A\n",
      "Epoch 0:   0%|          | 7/5011 [00:04<47:20,  1.76it/s]\u001b[A\n",
      "Epoch 0:   0%|          | 8/5011 [00:04<44:41,  1.87it/s]\u001b[A\n",
      "Epoch 0:   0%|          | 9/5011 [00:05<53:32,  1.56it/s]\u001b[A\n",
      "Total:   0%|          | 0/6 [00:05<?, ?it/s]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=4096, out_features=21, bias=True)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.ic_score1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def oicr_algorithm(xr0, gt_label, regions, K=3):\n",
    "K = 3\n",
    "R = regions.size()[1] # R\n",
    "# then do the online instance classifier refinement\n",
    "wrk_list = torch.zeros((K, R)).to(cfg.DEVICE)\n",
    "# R x 21 x k\n",
    "yrk_list = torch.zeros((K, R, (1 + len(VOC_CLASSES))))\n",
    "yrk_list[:, :, -1] = 1.0\n",
    "yrk_list = yrk_list.to(cfg.DEVICE)\n",
    "# here is just to calculate the supervi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Label is : 12\n",
      "top id : 826\n",
      "(tensor([596, 818, 826, 847, 874, 919, 920, 928], device='cuda:0'),)\n",
      "tensor([  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
      "          8.,   0.,   0.,   0.,   0.,   0.,   0.,   0., 951.], device='cuda:0')\n",
      "------------------------------\n",
      "True Label is : 14\n",
      "top id : 518\n",
      "(tensor([115, 127, 178, 210], device='cuda:0'),)\n",
      "tensor([  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
      "          8.,   0.,   4.,   0.,   0.,   0.,   0.,   0., 947.], device='cuda:0')\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    k = 1\n",
    "    xr0 = xrk_list\n",
    "    wrk = wrk_list[k, :]\n",
    "    yrk = yrk_list[k, :, :]\n",
    "    IoUs = torch.full((R, ), - np.inf).to(cfg.DEVICE)\n",
    "    for c in range(len(VOC_CLASSES)):\n",
    "        # 8 17\n",
    "        if gt_label[0][c] == 1.0:\n",
    "            print(\"True Label is : \" + str(c))\n",
    "            top_id = torch.argmax(xr0[k][:, c])\n",
    "            print(\"top id : \" + str(top_id.item()))\n",
    "            top_score = xr0[k][top_id][c]\n",
    "\n",
    "            top_box = regions[0][top_id:top_id+1]\n",
    "            IoUs_temp = one2allbox_iou(top_box, regions[0])\n",
    "            IoU_mask = torch.where(IoUs_temp > IoUs)\n",
    "            IoUs[IoU_mask] = IoUs_temp[IoU_mask]\n",
    "            wrk[IoU_mask] = top_score\n",
    "            y_mask = torch.where(IoUs[IoU_mask] > cfg.TRAIN.It)\n",
    "            yrk[y_mask] = 0.0\n",
    "            yrk[y_mask] += torch.eye(1 + len(VOC_CLASSES))[c].to(cfg.DEVICE)\n",
    "            print(y_mask)\n",
    "            print(yrk.sum(dim=0))\n",
    "            print('-' * 30)\n",
    "#             break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0016, 0.0439, 0.1009,  ..., 0.0006, 0.0003, 0.0003], device='cuda:0')"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "True Label is : 6\n",
    "top id : 452\n",
    "(tensor([ 54,  55,  58, 350, 352, 353, 386, 387, 388, 397, 446, 447, 448, 449,\n",
    "        450, 451, 452, 453, 454, 471, 473, 485, 486, 487, 525, 571, 651, 652,\n",
    "        705, 706, 812, 814, 822, 836, 837, 843], device='cuda:0'),)\n",
    "tensor([   0.,    0.,    0.,    0.,    0.,    0.,   36.,    0.,    0.,    0.,\n",
    "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
    "        1228.], device='cuda:0')\n",
    "------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0016, 0.0439, 0.1009,  ..., 0.0017, 0.0012, 0.0005], device='cuda:0')"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IoUs[torch.where(IoUs > 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "         0., 0.]], device='cuda:0')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2074, 21])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yrk_list[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sjjPy3",
   "language": "python",
   "name": "sjjpy3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
